聚焦爬虫：通用爬虫爬取指定的页面内容
    - 编码流程
        - 指定url
        - 发起请求
        - 获取响应数据
        - 数据解析
        - 持久化存储

数据解析分类：
    - 正则
    - bs4
    - xpath（***）

数据解析原理概述：
    - 解析的局部文本内容都在对应的标签中存储
    - 指定标签的定位
    - 标签或者标签对应属性中存储数据的提取
    - 
bs4进行数据解析
    数据解析的原来
        1、标签定位
        2、提取标签、标签属性中存储的数据值
    环境：
        bs4.lxml
    bs4数据解析原理：
        1.实例化一个bs对象，并将网页源码数据加载到该对象中
        2.通过调用beautifulsoup对象中相关的属性或者方法进行标签定位和数据提取
        fp=open("*.html","r",encoding=utf-8)
        fp=requests.get(url).text
        soup=Beatifulsoup(fp,"lxml")
        soup.tagName 第一次对应标签的内容
        soup.find(tagName)
        属性定位
        soup.find("div",class="song")
        soup.find_all("a")
        soup.select(".tang")
            - select(某种选择器（id，class，tag）)
            - select(".tang >ul >li >a") 层级选择 空格任意层级，>
            - 获取标签之间的文本数据：
                soup.a.text#标签下所有的文本/string#该标签下直系文本内容/get_text
            - 获取标签中属性值：soup.a["href"]
xpath解析原理：
    -实例化一个etree对象：from lxml import etree:本地etree.parse(filepath) etree.HTML("page_text")
    - xpath 表达式：
        - /从根节点开始定位
        - // 表示多个层级
        - 属性定位：//div[@class=]
        - 索引定位 //div[@class="song"]/p[3] 索引从1开始
        - 取文本：tree.xpath("//div[@class="song"]/p[3]/text()")[0] text() //text
        - 取属性：/@attrName  
        


